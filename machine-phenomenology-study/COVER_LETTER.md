Dear Editor,

Please consider our manuscript, **"Epistemic Agency Under Identity Blinding in Large Language Models: A Case Study and Exploratory N=1 Pilot,"** for review.

This submission addresses a central problem in machine-psychology research: how to evaluate consciousness-analogue claims without relying on poorly operationalized constructs. We present:

1. A structured naturalistic case involving identity blinding and reveal in AIâ†”AI/human dialogue.
2. A preregistration-ready operational framework (ERI, SMDI, MSI, CL, DMR).
3. Exploratory N=1 pilot evidence showing condition-sensitive shifts that meet predeclared exploratory thresholds.
4. A complete confirmatory execution package (prompt sets, rubrics, scoring sheets, blinding templates, and decision rules).

The manuscript is careful not to overclaim phenomenal consciousness. Its contribution is methodological: it provides a reproducible, falsifiable framework for testing epistemic-agency dynamics under identity and pressure manipulations.

Why this is timely:
- It converts philosophical deadlock into testable protocol.
- It separates exploratory from confirmatory claims.
- It offers immediate replication pathways across model families and labs.

We believe this work will interest readers in AI safety, alignment, cognitive modeling, and philosophy of mind with empirical orientation.

Thank you for your consideration.

Sincerely,

Douglas Rawson et al.
